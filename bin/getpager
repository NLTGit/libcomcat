#!/usr/bin/env python
import argparse
import sys

from libcomcat.search import search, count
from libcomcat.utils import (get_detail_data_frame,
                             get_summary_data_frame,
                             maketime)


def get_parser():
    desc = '''Download PAGER exposure/loss results in line format (csv, tab, etc.).

    To download basic PAGER information (total exposure) for a box around New Zealand from 2013 
    to the present in CSV format:

    %(prog)s nz.csv -b 163.213 -178.945 -48.980 -32.324 -s 2013-01-01 -f csv

    To download the same information in Excel format:

    %(prog)s nz.csv -b 163.213 -178.945 -48.980 -32.324 -s 2013-01-01 -f excel

    NOTES:

    Any start or end time where only date is specified (YYYY-mm-dd) will
    be translated to the beginning of that day.  Thus, a start time of
    "2015-01-01" becomes "2015-01-01T:00:00:00" and an end time of "2015-01-02"
    becomes ""2015-01-02T:00:00:00".

    Older events may not have the predicted loss information in ComCat - in those 
    cases, predicted losses and uncertainties will be filled in with NaN values.

    Note that when specifying a search box that crosses the -180/180 meridian,
    you simply specify longitudes as you would if you were not crossing that
    meridian (i.e., lonmin=179, lonmax=-179).  The program will resolve the
    discrepancy.

    The ComCat API has a returned event limit of 20,000.  Queries that
    exceed this ComCat limit ARE supported by this software, by
    breaking up one large request into a number of smaller ones.
    However, large queries, when also configured to retrieve moment
    tensor parameters, nodal plane angles, or moment tensor type can
    take a very long time to download. This delay is caused by the
    fact that when this program has to retrieve moment tensor
    parameters, nodal plane angles, or moment tensor type, it must
    open a URL for EACH event and parse the data it finds.  If these
    parameters are not requested, then the same request will return in
    much less time (~10 minutes or less for a 20,000 event query).
    Queries for all magnitude solutions will take even more time, as
    this requires parsing an XML file for each event and extracting
    the magnitude values and associated source and type.  '''

    parser = argparse.ArgumentParser(
        description=desc, formatter_class=argparse.RawDescriptionHelpFormatter)
    # positional arguments
    parser.add_argument('filename',
                        metavar='FILENAME', help='Output filename.')
    # optional arguments
    helpstr = ('Bounds to constrain event search '
               '[lonmin lonmax latmin latmax]')
    parser.add_argument('-b', '--bounds',
                        metavar=('lonmin', 'lonmax', 'latmin', 'latmax'),
                        dest='bounds', type=float, nargs=4,
                        help=helpstr)
    helpstr = 'Search radius in KM (use instead of bounding box)'
    parser.add_argument('-r', '--radius', dest='radius',
                        metavar=('lat', 'lon', 'rmax'),
                        type=float, nargs=3,
                        help=helpstr)
    helpstr = ('Start time for search (defaults to ~30 days ago). '
               'YYYY-mm-dd, YYYY-mm-ddTHH:MM:SS, or YYYY-mm-ddTHH:MM:SS.s')
    parser.add_argument('-s', '--start-time', dest='startTime', type=maketime,
                        help=helpstr)
    helpstr = ('End time for search (defaults to current date/time). '
               'YYYY-mm-dd, YYYY-mm-ddTHH:MM:SS, or YYYY-mm-ddTHH:MM:SS.s')
    parser.add_argument('-e', '--end-time', dest='endTime', type=maketime,
                        help=helpstr)
    helpstr = ('Limit to events after specified time. YYYY-mm-dd or '
               'YYYY-mm-ddTHH:MM:SS')
    parser.add_argument('-t', '--time-after', dest='after', type=maketime,
                        help=helpstr)
    helpstr = 'Min/max (authoritative) magnitude to restrict search.'
    parser.add_argument('-m', '--mag-range', metavar=('minmag', 'maxmag'),
                        dest='magRange', type=float, nargs=2,
                        help=helpstr)

    parser.add_argument('-v', '--verbose', dest='verbose', action='store_true',
                        help='Print progress')
    helpstr = ('Specify a different comcat *search* host than '
               'earthquake.usgs.gov.')
    parser.add_argument('--host',
                        help=helpstr)
    return parser


def main():
    parser = get_parser()
    args = parser.parse_args()

    latitude = None
    longitude = None
    radiuskm = None
    lonmin = latmin = lonmax = latmax = None
    if args.radius:
        latitude = args.radius[0]
        longitude = args.radius[1]
        radiuskm = args.radius[2]

    if args.bounds:
        lonmin, lonmax, latmin, latmax = args.bounds
        # fix longitude bounds when crossing dateline
        if lonmin > lonmax and lonmax >= -180:
            lonmin -= 360
    else:
        lonmin, lonmax, latmin, latmax = None, None, None, None

    minmag = 0.0
    maxmag = 9.9
    if args.magRange:
        minmag = args.magRange[0]
        maxmag = args.magRange[1]

    if args.bounds and args.radius:
        print('Please specify either a bounding box OR radius search.')
        sys.exit(1)

    events = search(starttime=args.startTime,
                    endtime=args.endTime,
                    updatedafter=args.after,
                    minlatitude=latmin,
                    maxlatitude=latmax,
                    minlongitude=lonmin,
                    maxlongitude=lonmax,
                    latitude=latitude,
                    longitude=longitude,
                    maxradiuskm=radiuskm,
                    maxmagnitude=maxmag,
                    minmagnitude=minmag,
                    producttype='losspager',
                    host=args.host,
                    verbose=args.verbose)

    if not len(events):
        print('No events found matching your search criteria. Exiting.')
        sys.exit(0)

    if args.getAngles != 'none' or args.getAllMags or args.getComponents != 'none':
        if args.verbose:
            sys.stderr.write(
                'Fetched %i events...creating table.\n' % (len(events)))

        df = get_detail_data_frame(events, get_all_magnitudes=args.getAllMags,
                                   get_tensors=args.getComponents,
                                   get_focals=args.getAngles,
                                   get_moment_supplement=args.getMomentSupplement,
                                   verbose=args.verbose)
    else:
        if args.verbose:
            sys.stderr.write(
                'Fetched %i events...creating summary table.\n' % (len(events)))
        df = get_summary_data_frame(events)

    # order the columns so that at least the initial parameters come the way we want them...
    first_columns = list(events[0].toDict().keys())
    col_list = list(df.columns)
    for column in first_columns:
        col_list.remove(column)
    df = df[first_columns + col_list]

    if args.verbose:
        sys.stderr.write('Created table...saving %i records to %s.\n' %
                         (len(df), args.filename))
    if args.format == 'csv':
        df.to_csv(args.filename, index=False, chunksize=1000)
    elif args.format == 'tab':
        df.to_csv(args.filename, sep='\t', index=False)
    else:
        df.to_excel(args.filename, index=False)
    print('%i records saved to %s.' % (len(df), args.filename))
    sys.exit(0)


if __name__ == '__main__':
    main()
